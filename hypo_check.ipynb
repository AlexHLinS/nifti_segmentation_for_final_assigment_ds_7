{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from typing import Any, Dict, Optional, Union, List, Tuple\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import wandb\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT, EPOCH_OUTPUT\n",
    "from torch.nn import Module, Conv2d, ConvTranspose2d, MaxPool2d, ReLU\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from nifti_tools import get_data_from_nifti_file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          image  \\\n0  datasets/Task02_Heart/imagesTr/la_007.nii.gz   \n1  datasets/Task02_Heart/imagesTr/la_019.nii.gz   \n\n                                          label  \n0  datasets/Task02_Heart/labelsTr/la_007.nii.gz  \n1  datasets/Task02_Heart/labelsTr/la_019.nii.gz  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>datasets/Task02_Heart/imagesTr/la_007.nii.gz</td>\n      <td>datasets/Task02_Heart/labelsTr/la_007.nii.gz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>datasets/Task02_Heart/imagesTr/la_019.nii.gz</td>\n      <td>datasets/Task02_Heart/labelsTr/la_019.nii.gz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_DIR = 'datasets/Task02_Heart/'\n",
    "CACHE_DIR = 'datasets/Task02_Heart/cache/'\n",
    "\n",
    "dataset_info = json.load(open(DATASET_DIR + 'dataset.json', 'r'))\n",
    "dataset_data = pd.dataset_data = pd.DataFrame(data=dataset_info['training'])\n",
    "dataset_data['image'] = dataset_data['image'].str.replace('./', DATASET_DIR, regex=False)\n",
    "dataset_data['label'] = dataset_data['label'].str.replace('./', DATASET_DIR, regex=False)\n",
    "dataset_data.head(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([130, 320, 320])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "d = get_data_from_nifti_file(dataset_data['image'][0], transponded=True)\n",
    "td = torch.Tensor(d)\n",
    "td.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    def normalize_data(self, x, y) -> Tuple:\n",
    "        x = x /2000\n",
    "        y[y>0.5] = 1\n",
    "        y[y<=0.5] = 0\n",
    "        return (x, y)\n",
    "\n",
    "    def save_layers_to_files(self, target_dir: str, layers, set_name: str) -> list:\n",
    "        i = 0\n",
    "        paths = []\n",
    "        for layer in layers:\n",
    "            filename = target_dir + set_name + '_' + str(i)\n",
    "            torch.save(torch.Tensor(layer), filename)\n",
    "            paths.append(filename)\n",
    "            i += 1\n",
    "        return paths\n",
    "\n",
    "    def __init__(self, data_paths: pd.DataFrame, cache_dir: str, image_converter=None, mask_converter=None,\n",
    "                 data_mutator=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_paths: Pandas DataFrame with the following columns 'image' and 'label', where exists paths to images and labels respectively\n",
    "            cache_dir: directory to extract and store tensors from nifti dataset (DIR MAST BE EXIST!)\n",
    "            image_converter: function applied to images when it loads from file\n",
    "            mask_converter: function applied to images when it loads from file\n",
    "            data_mutator: function applied to data when it loads from file (for example it will be normalizer)\n",
    "        \"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "        if os.path.isdir(self.cache_dir) is None:\n",
    "            try:\n",
    "                os.mkdir(self.cache_dir)\n",
    "            except OSError:\n",
    "                pprint('Cannot create cache directory!')\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.image_converter = image_converter\n",
    "        self.mask_converter = mask_converter\n",
    "        self.mutator = data_mutator\n",
    "\n",
    "        for i in range(data_paths.shape[0]):\n",
    "            image_data = get_data_from_nifti_file(data_paths['image'][i], transponded=True)\n",
    "            mask_data = get_data_from_nifti_file(data_paths['label'][i], transponded=True)\n",
    "            image_set_name = str(data_paths['image'][i]).split('/')[-1].split('.')[0] + '.image'\n",
    "            mask_set_name = str(data_paths['label'][i]).split('/')[-1].split('.')[0] + '.label'\n",
    "            self.image_paths += self.save_layers_to_files(cache_dir, image_data, image_set_name)\n",
    "            self.mask_paths += self.save_layers_to_files(cache_dir, mask_data, mask_set_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index) -> [torch.Tensor, torch.Tensor]:\n",
    "        image_filename = self.image_paths[index]\n",
    "        mask_filename = self.mask_paths[index]\n",
    "        image = torch.load(image_filename)\n",
    "        mask = torch.load(mask_filename)\n",
    "        return self.normalize_data(image, mask)\n",
    "\n",
    "    def __del__(self):\n",
    "        for file in self.image_paths:\n",
    "            os.remove(file)\n",
    "        for file in self.mask_paths:\n",
    "            os.remove(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "nds = NiftiDataset(dataset_data, CACHE_DIR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_ds_size = int(len(nds) * 0.7)\n",
    "test_ds_size = int(len(nds)) - train_ds_size\n",
    "train_ds, test_ds = data.random_split(nds, [train_ds_size, test_ds_size], generator=torch.Generator().manual_seed(1234))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_data = DataLoader(dataset=train_ds, shuffle=True, num_workers=0)\n",
    "test_data = DataLoader(dataset=test_ds, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class BaseElement(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.conv_1 = Conv2d(in_channels=input_size, out_channels=hidden_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_2 = Conv2d(in_channels=hidden_size, out_channels=output_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        return self.pool(x), x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class UNet(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_1 = BaseElement(input_size=1, hidden_size=64, output_size=64)\n",
    "        self.encoder_2 = BaseElement(input_size=64, hidden_size=128, output_size=128)\n",
    "        self.encoder_3 = BaseElement(input_size=128, hidden_size=256, output_size=256)\n",
    "        self.encoder_4 = BaseElement(input_size=256, hidden_size=512, output_size=512)\n",
    "        self.encoder_5 = BaseElement(input_size=512, hidden_size=1024, output_size=512)\n",
    "\n",
    "        self.decoder_1 = BaseElement(input_size=128, hidden_size=64, output_size=64)\n",
    "        self.decoder_2 = BaseElement(input_size=256, hidden_size=128, output_size=64)\n",
    "        self.decoder_3 = BaseElement(input_size=512, hidden_size=256, output_size=128)\n",
    "        self.decoder_4 = BaseElement(input_size=1024, hidden_size=512, output_size=256)\n",
    "\n",
    "        self.up_2_1 = ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.up_3_2 = ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.up_4_3 = ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.up_5_4 = ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=2, stride=2)\n",
    "\n",
    "        self.final = Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x [batch_size, 1, 320, 320]\n",
    "        #print(f'Enter point X shape:{x.shape} \\n')\n",
    "        x, encoded_1 = self.encoder_1(x)  # спускаем x, пробрасываем encoded_1\n",
    "        # x [batch_size, 64, 160, 160] ,encoded_1 [batch_size, 64, 320, 320]\n",
    "        #print(f'Down X:{x.shape}, after Encoder1:{encoded_1.shape}\\n')\n",
    "        x, encoded_2 = self.encoder_2(x)  # спускаем x, пробрасываем encoded_2\n",
    "        # x [batch_size, 128, 80, 80] ,encoded_2 [batch_size, 128, 160, 160]\n",
    "        #print(f'Down X:{x.shape}, after Encoder2:{encoded_2.shape}\\n')\n",
    "        x, encoded_3 = self.encoder_3(x)  # спускаем x, пробрасываем encoded_3\n",
    "        # x [batch_size, 256, 40, 40] ,encoded_3 [batch_size, 256, 80, 80]\n",
    "        #print(f'Down X:{x.shape}, after Encoder3:{encoded_3.shape}\\n')\n",
    "        x, encoded_4 = self.encoder_4(x)  # спускаем x, пробрасываем encoded_4\n",
    "        # x [batch_size, 512, 20, 20] ,encoded_4 [batch_size, 512, 40, 40]\n",
    "        #print(f'Down X:{x.shape}, after Encoder4:{encoded_4.shape}\\n')\n",
    "        _, x = self.encoder_5(x)  # получаем x \"внизу\"\n",
    "        # x [batch_size, 512, 20, 20]\n",
    "        #print(f'after Encoder5 X:{x.shape}\\n')\n",
    "        x = self.up_5_4(x)  # поднимаем x\n",
    "        # x [batch_size, 512, 40, 40]\n",
    "        # encoded_4 [batch_size, 512, 40, 40]\n",
    "        #print(f'up X: {x.shape}, after Encoder4:{encoded_4.shape}\\n')\n",
    "        x = torch.cat([x, encoded_4])  # объединяем с проброшенным encoded_4\n",
    "        # x [batch_size, 1024, 40, 40]\n",
    "        #print(f'merged X: {x.shape}\\n')\n",
    "        _, x = self.decoder_4(x)  # получаем x на выходе 4 декодера\n",
    "        # x [batch_size, 256, 40, 40]\n",
    "\n",
    "\n",
    "        x = self.up_4_3(x)  # поднимаем x\n",
    "        # x [batch_size, 256, 80, 80]\n",
    "        #encoded_3 [batch_size, 256, 80, 80]\n",
    "        x = torch.cat([x, encoded_3])  # объединяем с проброшенным encoded_3\n",
    "        # x [batch_size, 512, 80, 80]\n",
    "        _, x = self.decoder_3(x)  # получаем x на выходе 3 декодера\n",
    "        # x [batch_size, 128, 80, 80]\n",
    "        x = self.up_3_2(x)  # поднимаем x\n",
    "        # x [batch_size, 128, 160, 160]\n",
    "        # encoded_2 [batch_size, 128, 160, 160]\n",
    "        x = torch.cat([x, encoded_2])  # объединяем с проброшенным encoded_2\n",
    "        # x [batch_size, 256, 160, 160]\n",
    "        _, x = self.decoder_2(x)  # получаем x на выходе 2 декодера\n",
    "        # x [batch_size, 64, 160, 160]\n",
    "        x = self.up_2_1(x)  # поднимаем x\n",
    "        # x [batch_size, 64, 320, 320]\n",
    "        # encoded_1 [batch_size, 64, 320, 320]\n",
    "        x = torch.cat([x, encoded_1])  # объединяем с проброшенным encoded_1\n",
    "        # x [batch_size, 128, 320, 320]\n",
    "        _, x = self.decoder_1(x)  # получаем x на выходе 1 декодера\n",
    "        # x [batch_size, 64, 320, 320]\n",
    "\n",
    "        x = self.final(x)  # еще один слой на выходе\n",
    "        # x [batch_size, 1, 320, 320]\n",
    "\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class UNetModel1(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = UNet()\n",
    "        self.loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE,\n",
    "                                        from_logits=True)\n",
    "\n",
    "    def after_step(self, batch, stage) -> Dict:\n",
    "        \"\"\"\n",
    "        After each step calculate and returns metrics\n",
    "        Args:\n",
    "            batch:\n",
    "            stage:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        result = dict()\n",
    "        result['stage'] = stage\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        #print(f'X: {x.shape}, y: {y.shape}, y_hat: {y_hat.shape}')\n",
    "        result['loss'] = self.loss(y_hat, y)\n",
    "        y_prob = y_hat.sigmoid()\n",
    "        y_pred = (y_prob > 0.5).float()\n",
    "        result['true_positive'], result['false_positive'], \\\n",
    "            result['false_negative'], result['true_negative'] = smp.metrics.get_stats(y_pred.long(),\n",
    "                                                                                      y.long(),\n",
    "                                                                                      mode='binary')\n",
    "        return result\n",
    "\n",
    "    def after_epoch(self, outputs, stage):\n",
    "        \"\"\"\n",
    "        Calculate loss and metrics, then save them to log\n",
    "        Args:\n",
    "            outputs:\n",
    "            stage:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        true_positive = torch.cat([x[\"true_positive\"] for x in outputs])\n",
    "        false_positive = torch.cat([x[\"false_positive\"] for x in outputs])\n",
    "        false_negative = torch.cat([x[\"false_negative\"] for x in outputs])\n",
    "        true_negative = torch.cat([x[\"true_negative\"] for x in outputs])\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(len(outputs)): total_loss += outputs[i].get(f'{stage}_loss',0)\n",
    "\n",
    "        metrics_result = dict()\n",
    "\n",
    "        metrics_result[f'{stage}_recall'] = smp.metrics.recall(true_positive, false_positive, false_negative, true_negative, reduction=\"micro\")\n",
    "        metrics_result[f'{stage}_precision'] = smp.metrics.precision(true_positive, false_positive, false_negative, true_negative,\n",
    "                                          reduction=\"micro\")\n",
    "        metrics_result[f'{stage}_f1_score'] = smp.metrics.f1_score(true_positive, false_positive, false_negative, true_negative, reduction=\"micro\")\n",
    "        metrics_result[f'{stage}_accuracy'] = smp.metrics.accuracy(true_positive, false_positive, false_negative, true_negative, reduction=\"macro\")\n",
    "\n",
    "        self.log_dict(dictionary=metrics_result, prog_bar=True)\n",
    "\n",
    "\n",
    "    def forward(self, x) -> Any:\n",
    "        y = self.model(x)\n",
    "        return y\n",
    "\n",
    "    def training_step(self, batch, _) -> STEP_OUTPUT:\n",
    "        return self.after_step(batch=batch, stage='training')\n",
    "\n",
    "    def training_epoch_end(self, outputs: EPOCH_OUTPUT) -> None:\n",
    "        return self.after_epoch(outputs=outputs, stage='training')\n",
    "\n",
    "    def validation_step(self, batch, _) -> Optional[STEP_OUTPUT]:\n",
    "        return self.after_step(batch=batch, stage='validation')\n",
    "\n",
    "    def validation_epoch_end(self, outputs: Union[EPOCH_OUTPUT, List[EPOCH_OUTPUT]]) -> None:\n",
    "        return self.after_epoch(outputs=outputs, stage='validation')\n",
    "\n",
    "    def test_step(self, batch, _) -> Optional[STEP_OUTPUT]:\n",
    "        return self.after_step(batch=batch, stage='test')\n",
    "\n",
    "    def test_epoch_end(self, outputs: Union[EPOCH_OUTPUT, List[EPOCH_OUTPUT]]) -> None:\n",
    "        return self.after_epoch(outputs=outputs, stage='test')\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "callback = ModelCheckpoint(monitor=\"valid_f1_score\", mode='max', filename='best_valid_f1_score_model', save_top_k=1, save_weights_only=True)\n",
    "early_stop = EarlyStopping(monitor= \"valid_f1_score\", min_delta=0.00, patience = 20, verbose=True, mode=\"max\")\n",
    "SWA = StochasticWeightAveraging(swa_epoch_start=0.8, swa_lrs=0.001, annealing_epochs=5, annealing_strategy='cos')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33malexhlins\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /Users/alex/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.7"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/run-20230106_223756-3ixeflpq</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/alexhlins/HSE_DS7_Final/runs/3ixeflpq\" target=\"_blank\">Notebook</a></strong> to <a href=\"https://wandb.ai/alexhlins/HSE_DS7_Final\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:436: LightningDeprecationWarning: Setting `Trainer(num_processes=8)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='cpu', devices=8)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "with open('tokens/wandb.token', 'r') as tokenfile:\n",
    "    wandb_token = tokenfile.read().replace('/n', '')\n",
    "try:\n",
    "    wandb.finish()\n",
    "except Exception as e:\n",
    "    pprint(str(e))\n",
    "wandb.login(key=wandb_token)\n",
    "wandb_logger = WandbLogger(project='HSE_DS7_Final', name='Notebook')\n",
    "trainer = Trainer(logger=wandb_logger,\n",
    "                  enable_checkpointing=True,\n",
    "                  callbacks=[callback,early_stop, SWA],\n",
    "                  max_epochs=10,\n",
    "                  num_processes=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 8 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | UNet     | 23.4 M\n",
      "1 | loss  | DiceLoss | 0     \n",
      "-----------------------------------\n",
      "23.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.4 M    Total params\n",
      "93.480    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b340ecdc69844f9ab63bc553457fba2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n",
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('validation_recall', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n",
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('validation_precision', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n",
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('validation_f1_score', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n",
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('validation_accuracy', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f70cbc60e3244899a67a0a52141eb0e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[W reducer.cpp:1305] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/Users/alex/Documents/ВШЭ/final/code/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=UNetModel1(), train_dataloaders=train_data, val_dataloaders=test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
